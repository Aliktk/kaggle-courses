{
    "cells": [
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Introduction\n\nYou've built a model to identify clothing types in the **MNIST for Fashion** dataset.  Now you will make your model bigger, specify larger stride lengths and apply dropout. These changes will make your model faster and more accurate.\n\nThis is a last step in the **[Deep Learning Track](https://www.kaggle.com/learn/deep-learning)**.\n\n\n## Data Preparation\n**Run this cell of code.**\n"
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import keras\n\n# Set up code checking\nfrom learntools.core import binder\nbinder.bind(globals())\nfrom learntools.deep_learning.exercise_8 import *\nprint(\"Setup Complete\")\n\nimg_rows, img_cols = 28, 28\nnum_classes = 10\n\ndef prep_data(raw):\n    y = raw[:, 0]\n    out_y = keras.utils.to_categorical(y, num_classes)\n    \n    x = raw[:,1:]\n    num_images = raw.shape[0]\n    out_x = x.reshape(num_images, img_rows, img_cols, 1)\n    out_x = out_x / 255\n    return out_x, out_y\n\nfashion_file = \"../input/fashionmnist/fashion-mnist_train.csv\"\nfashion_data = np.loadtxt(fashion_file, skiprows=1, delimiter=',')\nx, y = prep_data(fashion_data)",
            "execution_count": 1,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Setup Complete\n",
                    "name": "stdout"
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# 1) Increasing Stride Size in A Layer\n\nBelow is a model without strides (or more accurately, with a stride length of 1)\n\nRun it. Notice it's accuracy and how long it takes per epoch. Then you will change the stride length in one of the layers."
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, Dropout\n\nbatch_size = 16\n\nfashion_model = Sequential()\nfashion_model.add(Conv2D(16, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))\nfashion_model.add(Conv2D(16, (3, 3), activation='relu'))\nfashion_model.add(Flatten())\nfashion_model.add(Dense(128, activation='relu'))\nfashion_model.add(Dense(num_classes, activation='softmax'))\n\nfashion_model.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\nfashion_model.fit(x, y,\n          batch_size=batch_size,\n          epochs=3,\n          validation_split = 0.2)\n",
            "execution_count": 2,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Train on 48000 samples, validate on 12000 samples\nEpoch 1/3\n48000/48000 [==============================] - 15s 318us/sample - loss: 0.4097 - acc: 0.8530 - val_loss: 0.3330 - val_acc: 0.8773\nEpoch 2/3\n48000/48000 [==============================] - 14s 287us/sample - loss: 0.2610 - acc: 0.9040 - val_loss: 0.2724 - val_acc: 0.9007\nEpoch 3/3\n48000/48000 [==============================] - 14s 299us/sample - loss: 0.1956 - acc: 0.9269 - val_loss: 0.2827 - val_acc: 0.9019\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 2,
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fa31c101a20>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "You have the same code in the cell below, but the model is now called `fashion_model_1`.  Change the specification of `fashion_model_1` so the second convolutional layer has a stride length of 2.\n\nRun the cell after you have done that. How does the speed and accuracy change compared to the first model you ran above?"
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "fashion_model_1 = Sequential()\nfashion_model_1.add(Conv2D(16, kernel_size=(3, 3),\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))\nfashion_model_1.add(Conv2D(16, (3, 3), activation='relu', strides=2))\nfashion_model_1.add(Flatten())\nfashion_model_1.add(Dense(128, activation='relu'))\nfashion_model_1.add(Dense(num_classes, activation='softmax'))\n\nfashion_model_1.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\n\nfashion_model_1.fit(x, y,\n          batch_size=batch_size,\n          epochs=3,\n          validation_split = 0.2)\nq_1.check()",
            "execution_count": 3,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Train on 48000 samples, validate on 12000 samples\nEpoch 1/3\n48000/48000 [==============================] - 13s 279us/sample - loss: 0.4293 - acc: 0.8467 - val_loss: 0.3524 - val_acc: 0.8754\nEpoch 2/3\n48000/48000 [==============================] - 13s 279us/sample - loss: 0.2920 - acc: 0.8923 - val_loss: 0.2951 - val_acc: 0.8957\nEpoch 3/3\n48000/48000 [==============================] - 13s 276us/sample - loss: 0.2346 - acc: 0.9125 - val_loss: 0.2766 - val_acc: 0.8978\n",
                    "name": "stdout"
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "<IPython.core.display.Javascript object>",
                        "application/javascript": "parent.postMessage({\"jupyterEvent\": \"custom.exercise_interaction\", \"data\": {\"outcomeType\": 1, \"valueTowardsCompletion\": 1.0, \"interactionType\": 1, \"questionType\": 2, \"learnTutorialId\": 83, \"questionId\": \"1_AddStrides\", \"learnToolsVersion\": \"0.3.2\", \"failureMessage\": \"\", \"exceptionClass\": \"\", \"trace\": \"\"}}, \"*\")"
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/plain": "None"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "For the solution, uncomment and run the cell below:"
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "#q_1.solution()",
            "execution_count": 4,
            "outputs": []
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "You should notice that your model training ran about twice as fast, but the accuracy change was trivial.  \n\nIn addition to being faster to train, this model is also faster at making predictions. This is very important in many scenarios. In practice, you'll need to decide whether that type of speed is important in the applications where you eventually apply deep learning models.\n\nYou could experiment with more layers or more convolutions in each layer. With some fine-tuning, you can build a model that is both faster and more accurate than the original model."
        },
        {
            "metadata": {
                "trusted": true
            },
            "cell_type": "code",
            "source": "model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 strides=1,\n                 activation='relu',\n                 input_shape=(img_rows, img_cols, 1)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(32, kernel_size=(3, 3), strides=1, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(48, kernel_size=(3, 3), strides=1, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(64, kernel_size=(3, 3), strides=1, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer='adam',\n              metrics=['accuracy'])\nmodel.fit(x, y,\n          batch_size=128,\n          epochs=6,\n          validation_split = 0.2)",
            "execution_count": 5,
            "outputs": [
                {
                    "output_type": "stream",
                    "text": "Train on 48000 samples, validate on 12000 samples\nEpoch 1/6\n48000/48000 [==============================] - 6s 134us/sample - loss: 0.5713 - acc: 0.7905 - val_loss: 0.3688 - val_acc: 0.8708\nEpoch 2/6\n48000/48000 [==============================] - 6s 125us/sample - loss: 0.3454 - acc: 0.8738 - val_loss: 0.3034 - val_acc: 0.8905\nEpoch 3/6\n48000/48000 [==============================] - 6s 126us/sample - loss: 0.2849 - acc: 0.8958 - val_loss: 0.2684 - val_acc: 0.9044\nEpoch 4/6\n48000/48000 [==============================] - 6s 124us/sample - loss: 0.2490 - acc: 0.9069 - val_loss: 0.2668 - val_acc: 0.9030\nEpoch 5/6\n48000/48000 [==============================] - 6s 124us/sample - loss: 0.2200 - acc: 0.9179 - val_loss: 0.2512 - val_acc: 0.9121\nEpoch 6/6\n48000/48000 [==============================] - 6s 123us/sample - loss: 0.1925 - acc: 0.9277 - val_loss: 0.2583 - val_acc: 0.9128\n",
                    "name": "stdout"
                },
                {
                    "output_type": "execute_result",
                    "execution_count": 5,
                    "data": {
                        "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7fa2e57b7c88>"
                    },
                    "metadata": {}
                }
            ]
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "# Congrats\nYou've finished the Deep Learning course.  You have the tools to create and tune computer vision models.  \n\nIf you feel like playing more with this dataset, you can open up a new code cell to experiment with different models (adding dropout, adding layers, etc.)  Or pick a new project and try out your skills.  \n\nA few fun datasets you might try include:\n- [Written letter recognition](https://www.kaggle.com/olgabelitskaya/classification-of-handwritten-letters)\n- [Flower Identification](https://www.kaggle.com/alxmamaev/flowers-recognition)\n- [Cats vs Dogs](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition)\n- [10 Monkeys](https://www.kaggle.com/slothkong/10-monkey-species)\n- [Predict Bone Age from X-Rays](https://www.kaggle.com/kmader/rsna-bone-age)\n\nYou have learned a lot, and you'll learn it as you practice. Have fun with it!"
        },
        {
            "metadata": {},
            "cell_type": "markdown",
            "source": "---\n**[Deep Learning Home Page](https://www.kaggle.com/learn/deep-learning)**\n\n\n\n\n\n*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}